{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 2.0.10 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "# env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726671e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Initial Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 2.0.10 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import Actor, Critic\n",
    "from ddpg_agent import Agent, OUNoise, ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "##Instantiate environment\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "# env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n"
     ]
    }
   ],
   "source": [
    "##Get 'environment' variables\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Instantiate Agent\n",
    "agent = Agent(state_size = state_size, action_size = action_size, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg_train(n_episodes=200, max_t=200, print_every=10):\n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    scores = []\n",
    "    reward_avg = []\n",
    "    \n",
    "    scores_avg = []\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        agent.reset()\n",
    "        \n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        state = env_info.vector_observations[0]\n",
    "        #states = env_info.vector_observations\n",
    "        score = 0\n",
    "        #score = np.zeros(num_agents)\n",
    "\n",
    "        reward_temp = 0\n",
    "        steps = 0\n",
    "        #print(i_episode)\n",
    "        \n",
    "        for t in range(max_t):\n",
    "            steps += 1\n",
    "            ##Determine action to take with clipping\n",
    "            action = agent.act(state, add_noise=True)\n",
    "            #actions = agent.act(states, add_noise=False)\n",
    "            \n",
    "            ##Execute action\n",
    "            env_info = env.step(action)[brain_name]\n",
    "            #env_info = env.step(actions)[brain_name]\n",
    "            \n",
    "            ##Get results of action\n",
    "            next_state = env_info.vector_observations[0]\n",
    "            reward = env_info.rewards[0]                  \n",
    "            done = env_info.local_done[0]  \n",
    "            #next_states = env_info.vector_observations\n",
    "            #rewards = env_info.rewards\n",
    "            #dones = env_info.local_done\n",
    "        \n",
    "            ##Update agent\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            #agent.step(states, actions, rewards, next_states, dones)\n",
    "            \n",
    "            ##Save scores\n",
    "            score += reward\n",
    "            #score += env_info.rewards\n",
    "            \n",
    "            state = next_state\n",
    "            #states = next_states\n",
    "            \n",
    "            #print(reward)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "            #if np.any(dones):\n",
    "            #    break\n",
    "        \n",
    "        print(reward_temp)\n",
    "        #print(type(reward_avg))\n",
    "        print('Score: ' + str(score))\n",
    "        reward_avg.append(score / steps)\n",
    "        \n",
    "        #reward_avg += [sum(reward_temp) / len(reward_temp)]\n",
    "        \n",
    "        scores_deque.append(score)\n",
    "        scores.append(score)\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)), end=\"\")\n",
    "        torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "        \n",
    "        scores_avg.append(np.mean(scores_deque))\n",
    "        print(reward_avg)\n",
    "\n",
    "    return scores, reward_avg, scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Score: 0.0\n",
      "Episode 1\tAverage Score: 0.00[0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/ddpg_agent.py:97: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(self.critic_local.parameters(), 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Score: 0.0\n",
      "Episode 2\tAverage Score: 0.00[0.0, 0.0]\n",
      "0\n",
      "Score: 0.0\n",
      "Episode 3\tAverage Score: 0.00[0.0, 0.0, 0.0]\n",
      "0\n",
      "Score: 0.0\n",
      "Episode 4\tAverage Score: 0.00[0.0, 0.0, 0.0, 0.0]\n",
      "0\n",
      "Score: 0.0\n",
      "Episode 5\tAverage Score: 0.00[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "0\n",
      "Score: 0.3999999910593033\n",
      "Episode 6\tAverage Score: 0.07[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011]\n",
      "0\n",
      "Score: 0.0\n",
      "Episode 7\tAverage Score: 0.06[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0]\n",
      "0\n",
      "Score: 0.0\n",
      "Episode 8\tAverage Score: 0.05[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0]\n",
      "0\n",
      "Score: 0.2899999935179949\n",
      "Episode 9\tAverage Score: 0.08[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829]\n",
      "0\n",
      "Score: 0.20999999530613422\n",
      "Episode 10\tAverage Score: 0.09[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808]\n",
      "0\n",
      "Score: 0.0\n",
      "Episode 11\tAverage Score: 0.08[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0]\n",
      "0\n",
      "Score: 0.1699999962002039\n",
      "Episode 12\tAverage Score: 0.09[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796]\n",
      "0\n",
      "Score: 0.5199999883770943\n",
      "Episode 13\tAverage Score: 0.12[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143]\n",
      "0\n",
      "Score: 0.17999999597668648\n",
      "Episode 14\tAverage Score: 0.13[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549]\n",
      "0\n",
      "Score: 0.0\n",
      "Episode 15\tAverage Score: 0.12[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0]\n",
      "0\n",
      "Score: 0.20999999530613422\n",
      "Episode 16\tAverage Score: 0.12[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808]\n",
      "0\n",
      "Score: 0.1099999975413084\n",
      "Episode 17\tAverage Score: 0.12[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028]\n",
      "0\n",
      "Score: 0.6199999861419201\n",
      "Episode 18\tAverage Score: 0.15[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067]\n",
      "0\n",
      "Score: 0.17999999597668648\n",
      "Episode 19\tAverage Score: 0.15[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549]\n",
      "0\n",
      "Score: 0.14999999664723873\n",
      "Episode 20\tAverage Score: 0.15[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291]\n",
      "0\n",
      "Score: 0.24999999441206455\n",
      "Episode 21\tAverage Score: 0.16[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819]\n",
      "0\n",
      "Score: 0.0\n",
      "Episode 22\tAverage Score: 0.15[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0]\n",
      "0\n",
      "Score: 0.05999999865889549\n",
      "Episode 23\tAverage Score: 0.15[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163]\n",
      "0\n",
      "Score: 0.0\n",
      "Episode 24\tAverage Score: 0.14[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0]\n",
      "0\n",
      "Score: 0.09999999776482582\n",
      "Episode 25\tAverage Score: 0.14[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275]\n",
      "0\n",
      "Score: 0.4599999897181988\n",
      "Episode 26\tAverage Score: 0.15[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275, 0.0015333332990606625]\n",
      "0\n",
      "Score: 0.8199999816715717\n",
      "Episode 27\tAverage Score: 0.18[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275, 0.0015333332990606625, 0.0027333332722385725]\n",
      "0\n",
      "Score: 0.4999999888241291\n",
      "Episode 28\tAverage Score: 0.19[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275, 0.0015333332990606625, 0.0027333332722385725, 0.0016666666294137638]\n",
      "0\n",
      "Score: 0.2799999937415123\n",
      "Episode 29\tAverage Score: 0.19[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275, 0.0015333332990606625, 0.0027333332722385725, 0.0016666666294137638, 0.0009333333124717076]\n",
      "0\n",
      "Score: 0.0\n",
      "Episode 30\tAverage Score: 0.18[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275, 0.0015333332990606625, 0.0027333332722385725, 0.0016666666294137638, 0.0009333333124717076, 0.0]\n",
      "0\n",
      "Score: 0.0\n",
      "Episode 31\tAverage Score: 0.18[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275, 0.0015333332990606625, 0.0027333332722385725, 0.0016666666294137638, 0.0009333333124717076, 0.0, 0.0]\n",
      "0\n",
      "Score: 0.0\n",
      "Episode 32\tAverage Score: 0.17[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275, 0.0015333332990606625, 0.0027333332722385725, 0.0016666666294137638, 0.0009333333124717076, 0.0, 0.0, 0.0]\n",
      "0\n",
      "Score: 0.05999999865889549\n",
      "Episode 33\tAverage Score: 0.17[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275, 0.0015333332990606625, 0.0027333332722385725, 0.0016666666294137638, 0.0009333333124717076, 0.0, 0.0, 0.0, 0.00019999999552965163]\n",
      "0\n",
      "Score: 0.029999999329447746\n",
      "Episode 34\tAverage Score: 0.16[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275, 0.0015333332990606625, 0.0027333332722385725, 0.0016666666294137638, 0.0009333333124717076, 0.0, 0.0, 0.0, 0.00019999999552965163, 9.999999776482581e-05]\n",
      "0\n",
      "Score: 0.19999999552965164\n",
      "Episode 35\tAverage Score: 0.17[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275, 0.0015333332990606625, 0.0027333332722385725, 0.0016666666294137638, 0.0009333333124717076, 0.0, 0.0, 0.0, 0.00019999999552965163, 9.999999776482581e-05, 0.0006666666517655055]\n",
      "0\n",
      "Score: 0.0\n",
      "Episode 36\tAverage Score: 0.16[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275, 0.0015333332990606625, 0.0027333332722385725, 0.0016666666294137638, 0.0009333333124717076, 0.0, 0.0, 0.0, 0.00019999999552965163, 9.999999776482581e-05, 0.0006666666517655055, 0.0]\n",
      "0\n",
      "Score: 0.1599999964237213\n",
      "Episode 37\tAverage Score: 0.16[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275, 0.0015333332990606625, 0.0027333332722385725, 0.0016666666294137638, 0.0009333333124717076, 0.0, 0.0, 0.0, 0.00019999999552965163, 9.999999776482581e-05, 0.0006666666517655055, 0.0, 0.0005333333214124044]\n",
      "0\n",
      "Score: 0.09999999776482582\n",
      "Episode 38\tAverage Score: 0.16[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275, 0.0015333332990606625, 0.0027333332722385725, 0.0016666666294137638, 0.0009333333124717076, 0.0, 0.0, 0.0, 0.00019999999552965163, 9.999999776482581e-05, 0.0006666666517655055, 0.0, 0.0005333333214124044, 0.00033333332588275275]\n",
      "0\n",
      "Score: 0.14999999664723873\n",
      "Episode 39\tAverage Score: 0.16[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275, 0.0015333332990606625, 0.0027333332722385725, 0.0016666666294137638, 0.0009333333124717076, 0.0, 0.0, 0.0, 0.00019999999552965163, 9.999999776482581e-05, 0.0006666666517655055, 0.0, 0.0005333333214124044, 0.00033333332588275275, 0.0004999999888241291]\n",
      "0\n",
      "Score: 0.2799999937415123\n",
      "Episode 40\tAverage Score: 0.16[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275, 0.0015333332990606625, 0.0027333332722385725, 0.0016666666294137638, 0.0009333333124717076, 0.0, 0.0, 0.0, 0.00019999999552965163, 9.999999776482581e-05, 0.0006666666517655055, 0.0, 0.0005333333214124044, 0.00033333332588275275, 0.0004999999888241291, 0.0009333333124717076]\n",
      "0\n",
      "Score: 0.24999999441206455\n",
      "Episode 41\tAverage Score: 0.16[0.0, 0.0, 0.0, 0.0, 0.0, 0.001333333303531011, 0.0, 0.0, 0.0009666666450599829, 0.0006999999843537808, 0.0, 0.0005666666540006796, 0.0017333332945903143, 0.0005999999865889549, 0.0, 0.0006999999843537808, 0.000366666658471028, 0.002066666620473067, 0.0005999999865889549, 0.0004999999888241291, 0.0008333333147068819, 0.0, 0.00019999999552965163, 0.0, 0.00033333332588275275, 0.0015333332990606625, 0.0027333332722385725, 0.0016666666294137638, 0.0009333333124717076, 0.0, 0.0, 0.0, 0.00019999999552965163, 9.999999776482581e-05, 0.0006666666517655055, 0.0, 0.0005333333214124044, 0.00033333332588275275, 0.0004999999888241291, 0.0009333333124717076, 0.0008333333147068819]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-226b7a712a8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddpg_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-c31c82256cda>\u001b[0m in \u001b[0;36mddpg_train\u001b[0;34m(n_episodes, max_t, print_every)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m##Update agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;31m#agent.step(states, actions, rewards, next_states, dones)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/workspace/ddpg_agent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mexperiences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/workspace/ddpg_agent.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, experiences, gamma)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m## Minimise loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mcritic_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores, reward_avg, scores_avg = ddpg_train(n_episodes=500, max_t=2000, print_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8aaea072b0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8aae9eb0f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
